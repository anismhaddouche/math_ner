{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "import spacy \n",
    "import sys\n",
    "sys.path.append('scripts')\n",
    "from utility import *\n",
    "from get_init import *\n",
    "import json \n",
    "import re \n",
    "import random \n",
    "from spacy.tokens import DocBin\n",
    "import jsonlines\n",
    "from spacy.tokens import Span\n",
    "from prodigy.components.db import connect\n",
    "from prettytable import PrettyTable\n",
    "import srsly\n",
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "from pysbd.utils import PySBDFactory\n",
    "from spacy.language import Language\n",
    "from spacy import displacy\n",
    "from spacy.pipeline.senter import DEFAULT_SENTER_MODEL\n",
    "from spacy.language import Language\n",
    "import pysbd\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import Span\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraire les délimiteurs de phrases HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@Language.component(\"pysbd_sentencizer\")\n",
    "def pysbd_sentence_boundaries(doc):\n",
    "    seg = pysbd.Segmenter(language=\"fr\", clean=False, char_span=True)\n",
    "    sents_char_spans = seg.segment(doc.text)\n",
    "    char_spans = [doc.char_span(sent_span.start, sent_span.end) for sent_span in sents_char_spans]\n",
    "    start_token_ids = [span[0].idx for span in char_spans if span is not None]\n",
    "    for token in doc:\n",
    "        token.is_sent_start = True if token.idx in start_token_ids else False\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'ner', 'pysbd_sentencizer']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"/Users/anis/test_labnbook/math_ner/train_ner/training/model-best\")\n",
    "nlp.add_pipe(\"pysbd_sentencizer\")\n",
    "\n",
    "text = \"Ceci est une equation : f(x)=x2x1 ? Ceci est une nouvelle phrase de la forme f(x)=ax+b+3 §   Ainsi blablabla  blablabla blablabla $$alpha+X+2$$ blablabla. De plus nous avons la table suivante suivantesuivante suivante suivante ¥ matable ¥ celle-ci www.yahoo-DZ.fr \"\n",
    "doc = nlp(text)\n",
    "# for sent in doc.sents:\n",
    "#     print(sent)``\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ceci est une equation : f(x)=x2x1 ? Ceci est une nouvelle phrase de la forme f(x)=ax+b+3 §   Ainsi blablabla  blablabla blablabla $$alpha+X+2$$ blablabla. De plus nous avons la table suivante suivantesuivante suivante suivante ¥ matable ¥ celle-ci www.yahoo-DZ.fr\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: ['Ceci est une equation : f(x)=x2x1 ? Ceci est une nouvelle phrase de la forme f(x)=ax+b+3 §', '  Ainsi blablabla  blablabla blablabla $$alpha+X+2$$ blablabla. De plus nous avons la table suivante suivantesuivante suivante suivante ¥ matable ¥ celle-ci www.yahoo-DZ.fr']\n"
     ]
    }
   ],
   "source": [
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text in [\"§\"]:\n",
    "            #print(\"token.text\", token.text)\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"set_custom_boundaries\")\n",
    "doc = nlp(text)\n",
    "print(\"After:\", [sent.text for sent in doc.sents])\n",
    "# for token in doc[:-1]:\n",
    "#     print(token.text, token.i, token.is_sent_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token.text §   \n",
      "token.text $ $\n",
      "token.text $ alpha+X+2$$\n",
      "token.text ¥ matable\n",
      "token.text ¥ celle-ci\n"
     ]
    }
   ],
   "source": [
    " for token in doc[:-1]:\n",
    "        if token.text in [\"§\",\"$\",\"¥\"]:\n",
    "            print(\"token.text\", token.text,doc[token.i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.find_streets(doc)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = {\n",
    "    \"LATEX_MATH\":  \"[$]{1,2}(.*?)[$]{1,2}\",\n",
    "    \"TABLE\":\"¥¥(.*?)¥¥\"\n",
    "        }\n",
    "@Language.component(\"Find_Latex-Table\")\n",
    "def find_streets(doc):\n",
    "    text = doc.text\n",
    "    camp_ents = []\n",
    "    original_ents = list(doc.ents)\n",
    "    for label, pattern in patterns.items():\n",
    "        for match in re.finditer(pattern, doc.text):\n",
    "            start, end = match.span()\n",
    "            span = doc.char_span(start, end)\n",
    "            if span is not None:\n",
    "                camp_ents.append((span.start, span.end, span.text))\n",
    "        for ent in camp_ents:\n",
    "            start, end, name = ent\n",
    "            per_ent = Span(doc, start, end, label=label)\n",
    "            original_ents.append(per_ent)\n",
    "        filtered = filter_spans(original_ents)\n",
    "        doc.ents = filtered\n",
    "    return (doc)\n",
    "nlp.add_pipe(\"Find_Latex-Table\", before=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'ner']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"/Users/anis/test_labnbook/math_ner/correct_ner/training/model-best\")\n",
    "text = \"Meubles qui sont encastrables=congélateur. §Meubles qui ne sont pas encastrables=lave-vaisselle, meuble bas et réfrigérateur. §Expliquez par quel raisonnement vous établissez vos conclusions : § J'ai calculé l'intervalle des valeurs que peuvent prendre les meubles dans cet espace en utilisant l'incertitude sur l'espace à meubler. Ainsi on obtient L=[592;602] en utilisant (597+/-5) mm. § Pour le lave vaisselle on a : L=(590+/-1)mm soit un intervalle [589;591] aucune des ces valeurs n'appartiennent à celles de l'intervalle de l'espace. § Pour le congélateur : L=(597+/-1)mm soit [596;598] ces valeurs sont comprises dans l'intervalle de l'espace à meubler donc il est encastrable. § Pour le meuble bas : L=(604+/-1)mm soit [603;605] ces valeurs ne sont pas comprises dans l'intervalle de l'espace meubler, donc il n'est pas encastrable. § Pour le réfrigérateur : L=(592+/-1)mm soit [591;593] ces valeurs ne sont pas totalement comprises dans l'intervalle de l'espace à meubler, donc il n'est pas encastrable. §\"\n",
    "doc = nlp(text)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Meubles qui sont \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    encastrables=congélateur\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       ". §Meubles qui ne sont pas \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    encastrables=lave-vaisselle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       ", meuble bas et réfrigérateur. §Expliquez par quel raisonnement vous établissez vos conclusions : § J'ai calculé l'intervalle des valeurs que peuvent prendre les meubles dans cet espace en utilisant l'incertitude sur l'espace à meubler. Ainsi on obtient L=[592;602] en utilisant (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    597+/-5) mm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       ". § Pour le lave vaisselle on a : L=(590+/-1)mm soit un intervalle \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [589;591]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       " aucune des ces valeurs n'appartiennent à celles de l'intervalle de l'espace. § Pour le congélateur : L=(597+/-1)mm soit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [596;598]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TEXT_MATH</span>\n",
       "</mark>\n",
       " ces valeurs sont comprises dans l'intervalle de l'espace à meubler donc il est encastrable. § Pour le meuble bas : L=(604+/-1)mm soit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [603;605]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       " ces valeurs ne sont pas comprises dans l'intervalle de l'espace meubler, donc il n'est pas encastrable. § Pour le réfrigérateur : L=(592+/-1)mm soit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [591;593]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TEXT_MATH</span>\n",
       "</mark>\n",
       " ces valeurs ne sont pas totalement comprises dans l'intervalle de l'espace à meubler, donc il n'est pas encastrable. §</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,jupyter=True ,style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Meubles qui sont \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    encastrables=congélateur\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       ". §Meubles qui ne sont pas \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    encastrables=lave-vaisselle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       ", meuble bas et réfrigérateur. §Expliquez par quel raisonnement vous établissez vos conclusions : § J'ai calculé l'intervalle des valeurs que peuvent prendre les meubles dans cet espace en utilisant l'incertitude sur l'espace à meubler. Ainsi on obtient L=[592;602] en utilisant (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    597+/-5) mm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       ". § Pour le lave vaisselle on a : L=(590+/-1)mm soit un intervalle \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [589;591]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       " aucune des ces valeurs n'appartiennent à celles de l'intervalle de l'espace. § Pour le congélateur : L=(597+/-1)mm soit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [596;598]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TEXT_MATH</span>\n",
       "</mark>\n",
       " ces valeurs sont comprises dans l'intervalle de l'espace à meubler donc il est encastrable. § Pour le meuble bas : L=(604+/-1)mm soit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [603;605]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       " ces valeurs ne sont pas comprises dans l'intervalle de l'espace meubler, donc il n'est pas encastrable. § Pour le réfrigérateur : L=(592+/-1)mm soit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [591;593]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TEXT_MATH</span>\n",
       "</mark>\n",
       " ces valeurs ne sont pas totalement comprises dans l'intervalle de l'espace à meubler, donc il n'est pas encastrable. §</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,jupyter=True ,style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'add_compoments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/anis/test_labnbook/math_ner/train_ner/test.ipynb Cellule 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anis/test_labnbook/math_ner/train_ner/test.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39madd_compoments\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'add_compoments'"
     ]
    }
   ],
   "source": [
    "from add_compoments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'Find_LatexTable' for language French (fr). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, entity_linker, ner, beam_ner, entity_ruler, lemmatizer, tagger, morphologizer, senter, sentencizer, textcat, spancat, textcat_multilabel, fr.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/anis/test_labnbook/math_ner/train_ner/test.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anis/test_labnbook/math_ner/train_ner/test.ipynb#ch0000015?line=0'>1</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/anis/test_labnbook/math_ner/correct_ner/training/model-best-updated\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     37\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     38\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     52\u001b[0m         name, vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig\n\u001b[1;32m     53\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/spacy/util.py:422\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(name, \u001b[39m\"\u001b[39m\u001b[39mexists\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# Path or Path-like to model data\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/spacy/util.py:488\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    486\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config)\n\u001b[1;32m    487\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[0;32m--> 488\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(config, vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    489\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/spacy/util.py:525\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[0;34m(config, vocab, disable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[1;32m    524\u001b[0m lang_cls \u001b[39m=\u001b[39m get_lang_class(nlp_config[\u001b[39m\"\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 525\u001b[0m nlp \u001b[39m=\u001b[39m lang_cls\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[1;32m    526\u001b[0m     config,\n\u001b[1;32m    527\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m    528\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m    529\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    530\u001b[0m     auto_fill\u001b[39m=\u001b[39;49mauto_fill,\n\u001b[1;32m    531\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    532\u001b[0m )\n\u001b[1;32m    533\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/spacy/language.py:1782\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[0;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1779\u001b[0m     factory \u001b[39m=\u001b[39m pipe_cfg\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfactory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1780\u001b[0m     \u001b[39m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m     \u001b[39m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[0;32m-> 1782\u001b[0m     nlp\u001b[39m.\u001b[39;49madd_pipe(\n\u001b[1;32m   1783\u001b[0m         factory,\n\u001b[1;32m   1784\u001b[0m         name\u001b[39m=\u001b[39;49mpipe_name,\n\u001b[1;32m   1785\u001b[0m         config\u001b[39m=\u001b[39;49mpipe_cfg,\n\u001b[1;32m   1786\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   1787\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[1;32m   1788\u001b[0m     )\n\u001b[1;32m   1789\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1790\u001b[0m     \u001b[39m# We need the sourced components to reference the same\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[39m# vocab without modifying the current vocab state **AND**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1796\u001b[0m     \u001b[39m# during deserialization, so they do not need any\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[39m# additional handling.\u001b[39;00m\n\u001b[1;32m   1798\u001b[0m     \u001b[39mif\u001b[39;00m vocab_b \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/spacy/language.py:792\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    785\u001b[0m         err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    786\u001b[0m             name\u001b[39m=\u001b[39mfactory_name,\n\u001b[1;32m    787\u001b[0m             opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m             lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[1;32m    791\u001b[0m         )\n\u001b[0;32m--> 792\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[1;32m    793\u001b[0m         factory_name,\n\u001b[1;32m    794\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    795\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    796\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[1;32m    797\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    798\u001b[0m     )\n\u001b[1;32m    799\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[1;32m    800\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/spacy/language.py:655\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    648\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    649\u001b[0m         name\u001b[39m=\u001b[39mfactory_name,\n\u001b[1;32m    650\u001b[0m         opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m         lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[1;32m    654\u001b[0m     )\n\u001b[0;32m--> 655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[1;32m    656\u001b[0m pipe_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n\u001b[1;32m    657\u001b[0m \u001b[39m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[39m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: [E002] Can't find factory for 'Find_LatexTable' for language French (fr). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, entity_linker, ner, beam_ner, entity_ruler, lemmatizer, tagger, morphologizer, senter, sentencizer, textcat, spancat, textcat_multilabel, fr.lemmatizer"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"/Users/anis/test_labnbook/math_ner/correct_ner/training/model-best-updated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'Find_Latex-Table', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ¥¥ceci¥ est¥ ma¥ table ¥¥\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TABLE</span>\n",
       "</mark>\n",
       " et ceci est une equation : \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    f(x)=x2x1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALUE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,jupyter=True ,style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tok2vec': [], 'ner': ['LATEX_MATH', 'TABLE', 'TEXT_MATH']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabnBook -- LabnBook -- 1.0\n",
      "LabnBook -- est -- 0.0\n",
      "LabnBook -- une -- 0.0\n",
      "LabnBook -- plateforme -- 0.0\n",
      "LabnBook -- numérique -- 0.0\n",
      "LabnBook -- et -- 0.0\n",
      "LabnBook -- gratuite -- 0.0\n",
      "LabnBook -- . -- 0.0\n",
      "est -- LabnBook -- 0.0\n",
      "est -- est -- 1.0\n",
      "est -- une -- 0.7295531630516052\n",
      "est -- plateforme -- 0.7295531630516052\n",
      "est -- numérique -- 0.6456043124198914\n",
      "est -- et -- 0.5657550096511841\n",
      "est -- gratuite -- 0.6456043124198914\n",
      "est -- . -- 0.14166748523712158\n",
      "une -- LabnBook -- 0.0\n",
      "une -- est -- 0.7295531630516052\n",
      "une -- une -- 1.0\n",
      "une -- plateforme -- 0.9999997615814209\n",
      "une -- numérique -- 0.812360942363739\n",
      "une -- et -- 0.572979748249054\n",
      "une -- gratuite -- 0.812360942363739\n",
      "une -- . -- 0.033962853252887726\n",
      "plateforme -- LabnBook -- 0.0\n",
      "plateforme -- est -- 0.7295531630516052\n",
      "plateforme -- une -- 0.9999997615814209\n",
      "plateforme -- plateforme -- 1.0\n",
      "plateforme -- numérique -- 0.812360942363739\n",
      "plateforme -- et -- 0.572979748249054\n",
      "plateforme -- gratuite -- 0.812360942363739\n",
      "plateforme -- . -- 0.033962853252887726\n",
      "numérique -- LabnBook -- 0.0\n",
      "numérique -- est -- 0.6456043124198914\n",
      "numérique -- une -- 0.812360942363739\n",
      "numérique -- plateforme -- 0.812360942363739\n",
      "numérique -- numérique -- 1.0\n",
      "numérique -- et -- 0.6270291805267334\n",
      "numérique -- gratuite -- 1.000000238418579\n",
      "numérique -- . -- -0.0006447795894928277\n",
      ". -- LabnBook -- 0.0\n",
      ". -- est -- 0.14166748523712158\n",
      ". -- une -- 0.033962853252887726\n",
      ". -- plateforme -- 0.033962853252887726\n",
      ". -- numérique -- -0.0006447795894928277\n",
      ". -- et -- 0.16336689889431\n",
      ". -- gratuite -- -0.0006447795894928277\n",
      ". -- . -- 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qz/t1vzp79913l2sfbf0b3d9sdr0000gn/T/ipykernel_48639/1820122094.py:8: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  print(token1,\"--\",token2,\"--\",token1.similarity(token2))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load('en_core_web_md')  # make sure to use larger model!\n",
    "student1 = nlp(u'LabnBook est une plateforme numérique.')\n",
    "student2 = nlp(u'LabnBook est une plateforme numérique et gratuite.') \n",
    "\n",
    "\n",
    "for token1 in student1:\n",
    "    for token2 in student2:\n",
    "        print(token1,\"--\",token2,\"--\",token1.similarity(token2))\n",
    "# student1.similarity(student2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keybert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/anis/test_labnbook/math_ner/train_ner/test.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anis/test_labnbook/math_ner/train_ner/test.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeybert\u001b[39;00m \u001b[39mimport\u001b[39;00m KeyBERT\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keybert'"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7bae802a98f43a68296acc593990a17ba8bb804956ac47e96ba419f2775cbfc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
